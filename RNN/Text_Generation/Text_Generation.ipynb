{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56358da0-a890-445f-80b3-46dfa1bb9812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:28:09.244410Z",
     "iopub.status.busy": "2023-05-07T17:28:09.243811Z",
     "iopub.status.idle": "2023-05-07T17:28:14.746368Z",
     "shell.execute_reply": "2023-05-07T17:28:14.745668Z",
     "shell.execute_reply.started": "2023-05-07T17:28:09.244384Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 22:58:11.709270: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import string\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d390545-6ff7-4354-b6b4-ec2de536d0bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:28:14.748588Z",
     "iopub.status.busy": "2023-05-07T17:28:14.747990Z",
     "iopub.status.idle": "2023-05-07T17:28:14.769807Z",
     "shell.execute_reply": "2023-05-07T17:28:14.768940Z",
     "shell.execute_reply.started": "2023-05-07T17:28:14.748565Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('data/ArticlesApril2017.csv')\n",
    "# len(df.headline.values)\n",
    "\n",
    "\n",
    "curr_directory = 'data/'\n",
    "all_headlines = []\n",
    "for filename in os.listdir(curr_directory):\n",
    "    if 'Article' in filename:\n",
    "        # print(filename)\n",
    "        df = pd.read_csv(curr_directory + filename)\n",
    "        all_headlines.extend(df.headline.values)\n",
    "        break\n",
    "\n",
    "all_headlines = [headline for headline in all_headlines if headline != 'Unknown' ]\n",
    "len(all_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac74985-c410-4b71-9b69-c8b30228aaeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:28:14.771380Z",
     "iopub.status.busy": "2023-05-07T17:28:14.771005Z",
     "iopub.status.idle": "2023-05-07T17:28:14.777287Z",
     "shell.execute_reply": "2023-05-07T17:28:14.776304Z",
     "shell.execute_reply.started": "2023-05-07T17:28:14.771358Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N.F.L. vs. Politics Has Been Battle All Season Long',\n",
       " 'Voice. Vice. Veracity.',\n",
       " 'A Stand-Up’s Downward Slide',\n",
       " 'New York Today: A Groundhog Has Her Day',\n",
       " 'A Swimmer’s Communion With the Ocean',\n",
       " 'Trail Activity',\n",
       " 'Super Bowl',\n",
       " 'Trump’s Mexican Shakedown',\n",
       " 'Pence’s Presidential Pet',\n",
       " 'Fruit of a Poison Tree']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_headlines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04339f8f-0a95-451d-905f-3ad715ac97f6",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ec5f44-d96a-4fd6-84ad-ca9357362b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:28:16.889414Z",
     "iopub.status.busy": "2023-05-07T17:28:16.889133Z",
     "iopub.status.idle": "2023-05-07T17:28:16.901051Z",
     "shell.execute_reply": "2023-05-07T17:28:16.899718Z",
     "shell.execute_reply.started": "2023-05-07T17:28:16.889394Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nfl vs politics has been battle all season long',\n",
       " 'voice vice veracity',\n",
       " 'a standups downward slide',\n",
       " 'new york today a groundhog has her day',\n",
       " 'a swimmers communion with the ocean',\n",
       " 'trail activity',\n",
       " 'super bowl',\n",
       " 'trumps mexican shakedown',\n",
       " 'pences presidential pet',\n",
       " 'fruit of a poison tree']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode('utf-8').decode('ascii','ignore')\n",
    "    return txt\n",
    "\n",
    "corpus = [clean_text(txt) for txt in all_headlines]\n",
    "corpus[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee977da6-a0b6-4f68-990e-fa89fcca475f",
   "metadata": {},
   "source": [
    "# N-Gram Tokens Padded and Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251ab9fb-26bf-495a-bebf-997106e238c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:28:18.108095Z",
     "iopub.status.busy": "2023-05-07T17:28:18.107469Z",
     "iopub.status.idle": "2023-05-07T17:28:18.257968Z",
     "shell.execute_reply": "2023-05-07T17:28:18.256814Z",
     "shell.execute_reply.started": "2023-05-07T17:28:18.108071Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[660, 117],\n",
       " [660, 117, 72],\n",
       " [660, 117, 72, 73],\n",
       " [660, 117, 72, 73, 661],\n",
       " [660, 117, 72, 73, 661, 662],\n",
       " [660, 117, 72, 73, 661, 662, 63],\n",
       " [660, 117, 72, 73, 661, 662, 63, 29],\n",
       " [660, 117, 72, 73, 661, 662, 63, 29, 210],\n",
       " [211, 663],\n",
       " [211, 663, 664]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = Tokenizer()\n",
    "\n",
    "def token_generator(corpus):\n",
    "    tk.fit_on_texts(corpus)\n",
    "    vocab_size = len(tk.word_index)+1\n",
    "    \n",
    "    input_sequence = []\n",
    "    for seq in corpus:\n",
    "        seq_list = tk.texts_to_sequences([seq])[0]\n",
    "        for i in range(1,len(seq_list)):\n",
    "            input_sequence.append(seq_list[:i+1])\n",
    "        \n",
    "    return input_sequence,vocab_size\n",
    "    \n",
    "\n",
    "input_sequence,vocab_size = token_generator(corpus)\n",
    "print(vocab_size)\n",
    "input_sequence[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37f888d-3cfd-4b92-886a-aae64434add9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:29:09.091624Z",
     "iopub.status.busy": "2023-05-07T17:29:09.091276Z",
     "iopub.status.idle": "2023-05-07T17:29:09.106945Z",
     "shell.execute_reply": "2023-05-07T17:29:09.106308Z",
     "shell.execute_reply.started": "2023-05-07T17:29:09.091598Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def padded_data_generator(input_sequence):\n",
    "    max_len = max([len(x) for x in input_sequence])\n",
    "    input_sequence = pad_sequences(input_sequence,maxlen=max_len)\n",
    "    \n",
    "    data,target = input_sequence[:,:-1],input_sequence[:,-1]\n",
    "    # target = to_categorical(target)\n",
    "    return data, target, max_len\n",
    "\n",
    "data,target,seq_length = padded_data_generator(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d1058a0-5869-4c0d-9f16-2349c3aa8ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:29:10.186087Z",
     "iopub.status.busy": "2023-05-07T17:29:10.185788Z",
     "iopub.status.idle": "2023-05-07T17:29:10.190384Z",
     "shell.execute_reply": "2023-05-07T17:29:10.189538Z",
     "shell.execute_reply.started": "2023-05-07T17:29:10.186066Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4544,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2e2979-b237-4ff5-9c18-1895ceca3a40",
   "metadata": {},
   "source": [
    "# LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a884d650-7159-488e-a0c2-706c30f926db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:29:45.524366Z",
     "iopub.status.busy": "2023-05-07T17:29:45.524023Z",
     "iopub.status.idle": "2023-05-07T17:29:45.796867Z",
     "shell.execute_reply": "2023-05-07T17:29:45.796169Z",
     "shell.execute_reply.started": "2023-05-07T17:29:45.524342Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 16, 10)            22880     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               44400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2288)              231088    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 298368 (1.14 MB)\n",
      "Trainable params: 298368 (1.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,10, input_length=seq_length-1),\n",
    "    # Dropout(0.2),\n",
    "    LSTM(units=100, dropout=0.1),\n",
    "    Dense(vocab_size, activation = 'softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29d31ab-83cb-4103-adc3-d3c3d8429c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:29:55.538381Z",
     "iopub.status.busy": "2023-05-07T17:29:55.538042Z",
     "iopub.status.idle": "2023-05-07T17:33:00.605333Z",
     "shell.execute_reply": "2023-05-07T17:33:00.604644Z",
     "shell.execute_reply.started": "2023-05-07T17:29:55.538354Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "142/142 [==============================] - 2s 6ms/step - loss: 7.3656 - accuracy: 0.0376\n",
      "Epoch 2/100\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 6.8534 - accuracy: 0.0392\n",
      "Epoch 3/100\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 6.7354 - accuracy: 0.0392\n",
      "Epoch 4/100\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 6.6547 - accuracy: 0.0392\n",
      "Epoch 5/100\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 6.5749 - accuracy: 0.0420\n",
      "Epoch 6/100\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.4941 - accuracy: 0.0425\n",
      "Epoch 7/100\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.4030 - accuracy: 0.0493\n",
      "Epoch 8/100\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.3075 - accuracy: 0.0513\n",
      "Epoch 9/100\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.2092 - accuracy: 0.0537\n",
      "Epoch 10/100\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.1149 - accuracy: 0.0563\n",
      "Epoch 11/100\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 6.0291 - accuracy: 0.0588\n",
      "Epoch 12/100\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 5.9454 - accuracy: 0.0577\n",
      "Epoch 13/100\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 5.8620 - accuracy: 0.0599\n",
      "Epoch 14/100\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 5.7764 - accuracy: 0.0660\n",
      "Epoch 15/100\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 5.7005 - accuracy: 0.0638\n",
      "Epoch 16/100\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 5.6186 - accuracy: 0.0667\n",
      "Epoch 17/100\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 5.5363 - accuracy: 0.0704\n",
      "Epoch 18/100\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 5.4535 - accuracy: 0.0713\n",
      "Epoch 19/100\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 5.3708 - accuracy: 0.0724\n",
      "Epoch 20/100\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 5.2934 - accuracy: 0.0770\n",
      "Epoch 21/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 5.2145 - accuracy: 0.0823\n",
      "Epoch 22/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 5.1358 - accuracy: 0.0874\n",
      "Epoch 23/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 5.0599 - accuracy: 0.0849\n",
      "Epoch 24/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 4.9826 - accuracy: 0.0904\n",
      "Epoch 25/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 4.9052 - accuracy: 0.0920\n",
      "Epoch 26/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 4.8320 - accuracy: 0.0982\n",
      "Epoch 27/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 4.7579 - accuracy: 0.0982\n",
      "Epoch 28/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 4.6847 - accuracy: 0.1063\n",
      "Epoch 29/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 4.6156 - accuracy: 0.1122\n",
      "Epoch 30/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 4.5454 - accuracy: 0.1142\n",
      "Epoch 31/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 4.4709 - accuracy: 0.1210\n",
      "Epoch 32/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 4.4083 - accuracy: 0.1263\n",
      "Epoch 33/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 4.3481 - accuracy: 0.1323\n",
      "Epoch 34/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 4.2780 - accuracy: 0.1411\n",
      "Epoch 35/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 4.2138 - accuracy: 0.1496\n",
      "Epoch 36/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 4.1513 - accuracy: 0.1560\n",
      "Epoch 37/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 4.0896 - accuracy: 0.1677\n",
      "Epoch 38/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 4.0293 - accuracy: 0.1723\n",
      "Epoch 39/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 3.9699 - accuracy: 0.1827\n",
      "Epoch 40/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 3.9103 - accuracy: 0.1915\n",
      "Epoch 41/100\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 3.8526 - accuracy: 0.2033\n",
      "Epoch 42/100\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 3.7949 - accuracy: 0.2064\n",
      "Epoch 43/100\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 3.7402 - accuracy: 0.2174\n",
      "Epoch 44/100\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 3.6888 - accuracy: 0.2304\n",
      "Epoch 45/100\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 3.6342 - accuracy: 0.2331\n",
      "Epoch 46/100\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 3.5827 - accuracy: 0.2478\n",
      "Epoch 47/100\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 3.5332 - accuracy: 0.2522\n",
      "Epoch 48/100\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 3.4823 - accuracy: 0.2700\n",
      "Epoch 49/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 3.4407 - accuracy: 0.2700\n",
      "Epoch 50/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 3.3951 - accuracy: 0.2819\n",
      "Epoch 51/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 3.3457 - accuracy: 0.2909\n",
      "Epoch 52/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 3.2981 - accuracy: 0.3004\n",
      "Epoch 53/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 3.2577 - accuracy: 0.3090\n",
      "Epoch 54/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 3.2154 - accuracy: 0.3154\n",
      "Epoch 55/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 3.1723 - accuracy: 0.3250\n",
      "Epoch 56/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 3.1315 - accuracy: 0.3303\n",
      "Epoch 57/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 3.0893 - accuracy: 0.3460\n",
      "Epoch 58/100\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 3.0547 - accuracy: 0.3501\n",
      "Epoch 59/100\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 3.0217 - accuracy: 0.3567\n",
      "Epoch 60/100\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 2.9778 - accuracy: 0.3633\n",
      "Epoch 61/100\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 2.9464 - accuracy: 0.3660\n",
      "Epoch 62/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 2.9129 - accuracy: 0.3728\n",
      "Epoch 63/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 2.8782 - accuracy: 0.3772\n",
      "Epoch 64/100\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 2.8463 - accuracy: 0.3820\n",
      "Epoch 65/100\n",
      "142/142 [==============================] - 1s 11ms/step - loss: 2.8127 - accuracy: 0.3917\n",
      "Epoch 66/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 2.7787 - accuracy: 0.3966\n",
      "Epoch 67/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 2.7465 - accuracy: 0.3996\n",
      "Epoch 68/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 2.7114 - accuracy: 0.4104\n",
      "Epoch 69/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 2.6939 - accuracy: 0.4146\n",
      "Epoch 70/100\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 2.6618 - accuracy: 0.4166\n",
      "Epoch 71/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 2.6259 - accuracy: 0.4274\n",
      "Epoch 72/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 2.6063 - accuracy: 0.4307\n",
      "Epoch 73/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 2.5738 - accuracy: 0.4360\n",
      "Epoch 74/100\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 2.5522 - accuracy: 0.4355\n",
      "Epoch 75/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 2.5265 - accuracy: 0.4452\n",
      "Epoch 76/100\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 2.4960 - accuracy: 0.4472\n",
      "Epoch 77/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 2.4754 - accuracy: 0.4547\n",
      "Epoch 78/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 2.4444 - accuracy: 0.4553\n",
      "Epoch 79/100\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 2.4174 - accuracy: 0.4646\n",
      "Epoch 80/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 2.3926 - accuracy: 0.4648\n",
      "Epoch 81/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 2.3710 - accuracy: 0.4707\n",
      "Epoch 82/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 2.3494 - accuracy: 0.4769\n",
      "Epoch 83/100\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 2.3271 - accuracy: 0.4839\n",
      "Epoch 84/100\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 2.2997 - accuracy: 0.4870\n",
      "Epoch 85/100\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 2.2813 - accuracy: 0.4934\n",
      "Epoch 86/100\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 2.2559 - accuracy: 0.4943\n",
      "Epoch 87/100\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 2.2326 - accuracy: 0.5002\n",
      "Epoch 88/100\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 2.2180 - accuracy: 0.5066\n",
      "Epoch 89/100\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 2.1959 - accuracy: 0.5062\n",
      "Epoch 90/100\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 2.1829 - accuracy: 0.5134\n",
      "Epoch 91/100\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 2.1518 - accuracy: 0.5134\n",
      "Epoch 92/100\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 2.1379 - accuracy: 0.5290\n",
      "Epoch 93/100\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 2.1149 - accuracy: 0.5246\n",
      "Epoch 94/100\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 2.1060 - accuracy: 0.5253\n",
      "Epoch 95/100\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 2.0744 - accuracy: 0.5343\n",
      "Epoch 96/100\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 2.0522 - accuracy: 0.5438\n",
      "Epoch 97/100\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 2.0469 - accuracy: 0.5405\n",
      "Epoch 98/100\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 2.0299 - accuracy: 0.5464\n",
      "Epoch 99/100\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 2.0033 - accuracy: 0.5508\n",
      "Epoch 100/100\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 1.9956 - accuracy: 0.5458\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(data,target,epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b476d9db-8b70-471d-9882-ff58c78d21fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T19:17:58.132403Z",
     "iopub.status.busy": "2023-05-07T19:17:58.131620Z",
     "iopub.status.idle": "2023-05-07T19:17:59.136357Z",
     "shell.execute_reply": "2023-05-07T19:17:59.135767Z",
     "shell.execute_reply.started": "2023-05-07T19:17:58.132367Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States Regulation Limit The Light Coming\n",
      "India In The Bookshelf Winemaker Put Make In\n",
      "Beautiful Mailbag Why Treat A\n",
      "Dog I Is The Jews Board\n",
      "Hello Question In A Dusty Bottle\n"
     ]
    }
   ],
   "source": [
    "def text_generation(seed_text,number_of_words_req,seq_length,model):\n",
    "    for _ in range(number_of_words_req):\n",
    "        token_list = tk.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list],seq_length-1)\n",
    "        y_pred = np.argmax(model.predict(token_list,verbose = 0))\n",
    "\n",
    "        # print(y_pred)\n",
    "        output = \"\"\n",
    "        for word,index in tk.word_index.items():\n",
    "            if(y_pred == index):\n",
    "                # print(word)\n",
    "                output = word\n",
    "                break\n",
    "\n",
    "        seed_text += \" \" + word\n",
    "        # print(seed_text.title())\n",
    "    return seed_text.title()\n",
    "    \n",
    "print(text_generation(\"united states\",5,seq_length,model))\n",
    "print(text_generation(\"india\",7,seq_length,model))\n",
    "print(text_generation(\"beautiful\",4,seq_length,model))\n",
    "print(text_generation(\"dog\",5,seq_length,model))\n",
    "print(text_generation(\"hello\",5,seq_length,model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd24866-cb6f-45bb-acd9-315869f4ad86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
